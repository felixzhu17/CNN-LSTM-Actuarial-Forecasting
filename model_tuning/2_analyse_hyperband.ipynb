{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "project_root = os.path.abspath('..')\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from methods.config import *\n",
    "from methods.var import get_VAR_results\n",
    "from methods.nn import get_NN_results, get_model_name\n",
    "from methods.data_methods import prepare_model_data\n",
    "from methods.clean_data import Data_Prep\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers import Dense, LSTM, Flatten, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for end_year in PERIODS_MAP.values():\n",
    "    for output_steps in OUTPUT_STEPS:\n",
    "        for variable in TARGET_VARIABLES:\n",
    "\n",
    "          pickle_file_path = os.path.join(TUNING_RESULTS_PATH, f\"{end_year}_{output_steps}_{variable}_results.pkl\")\n",
    "          if os.path.isfile(pickle_file_path):\n",
    "              print(f\"Skipping loop for {end_year}_{output_steps}_{variable} because Pickle file already exists.\")\n",
    "              continue\n",
    "\n",
    "          results = []\n",
    "          for look_back_year in LOOK_BACK_YEARS:\n",
    "            for number_of_pca in NUMBER_OF_PCAS:\n",
    "                    look_back_steps = int(look_back_year * 12)\n",
    "                    data_prep = Data_Prep(DATA_PATH, TRANSFORM_PATH)\n",
    "                    data_prep.transform_to_supervised_learning(\n",
    "                        NA_CUTOFF,\n",
    "                        [variable],\n",
    "                        output_steps,\n",
    "                        start=f\"{START_YEAR}-01-01\",\n",
    "                        end=f\"{end_year}-01-01\",\n",
    "                    )\n",
    "                    dataset = data_prep.supervised_dataset\n",
    "                    full_dataset = dataset[\"transformed_data\"]\n",
    "                    data = prepare_model_data(\n",
    "                        window=full_dataset,\n",
    "                        X_variables=dataset[\"X_variables\"],\n",
    "                        Y_variables=dataset[\"Y_variables\"],\n",
    "                        val_steps=VAL_STEPS,\n",
    "                        look_back=look_back_steps,\n",
    "                        test_steps=TEST_STEPS,\n",
    "                        remove_outlier=REMOVE_OUTLIER,\n",
    "                        number_of_pca=number_of_pca,\n",
    "                        target_variables=TARGET_VARIABLES,\n",
    "                    )\n",
    "\n",
    "                    # Adjust size to match batch\n",
    "                    data[\"train_X\"] = data[\"train_X\"][\n",
    "                        len(data[\"train_X\"]) % BATCH_SIZE :\n",
    "                    ]\n",
    "                    data[\"train_Y\"] = data[\"train_Y\"][\n",
    "                        len(data[\"train_Y\"]) % BATCH_SIZE :\n",
    "                    ]\n",
    "\n",
    "                    NAME = get_model_name(\n",
    "                        end_year,\n",
    "                        variable,\n",
    "                        FREQUENCY,\n",
    "                        output_steps,\n",
    "                        look_back_year,\n",
    "                        REMOVE_OUTLIER,\n",
    "                        VAL_YEARS,\n",
    "                        number_of_pca,\n",
    "                    )\n",
    "\n",
    "                    print(f\"Evaluating {NAME}\")\n",
    "\n",
    "                    best_model = load_model(os.path.join(TUNING_MODELS_PATH, f\"{NAME}.h5\"))\n",
    "                    with open(os.path.join(TUNING_PARAMS_PATH, f\"{NAME}.json\"), 'r') as f:\n",
    "                        best_hp = json.load(f)\n",
    "\n",
    "\n",
    "                    NN_results = get_NN_results(\n",
    "                        best_model,\n",
    "                        data,\n",
    "                        VAL_STEPS,\n",
    "                        TEST_STEPS,\n",
    "                        look_back_steps,\n",
    "                        dataset,\n",
    "                        BATCH_SIZE,\n",
    "                        EPOCHS,\n",
    "                        executions=3,\n",
    "                    )\n",
    "\n",
    "                    data_prep.transform_to_supervised_learning(\n",
    "                        NA_CUTOFF,\n",
    "                        TARGET_VARIABLES,\n",
    "                        output_steps=output_steps,\n",
    "                        start=f\"{START_YEAR}-01-01\",\n",
    "                        end=f\"{end_year}-01-01\",\n",
    "                    )\n",
    "                    var_dataset = data_prep.supervised_dataset\n",
    "                    Var_results = get_VAR_results(\n",
    "                        var_dataset,\n",
    "                        test_steps=TEST_STEPS,\n",
    "                        val_steps=VAL_STEPS,\n",
    "                        output_steps=output_steps,\n",
    "                    )\n",
    "\n",
    "                    val_result = {\n",
    "                        k: v / Var_results[\"val\"][\"error\"][k]\n",
    "                        for k, v in NN_results[\"val\"][\"error\"].items()\n",
    "                    }\n",
    "                    val_result[\"average\"] = sum(val_result.values()) / len(\n",
    "                        val_result.values()\n",
    "                    )\n",
    "                    val_result_raw = {\n",
    "                        k: v / Var_results[\"val\"][\"error_raw\"][k]\n",
    "                        for k, v in NN_results[\"val\"][\"error_raw\"].items()\n",
    "                    }\n",
    "\n",
    "                    test_result = {\n",
    "                        k: v / Var_results[\"test\"][\"error\"][k]\n",
    "                        for k, v in NN_results[\"test\"][\"error\"].items()\n",
    "                    }\n",
    "                    test_result[\"average\"] = sum(test_result.values()) / len(\n",
    "                        test_result.values()\n",
    "                    )\n",
    "                    test_result_raw = {\n",
    "                        k: v / Var_results[\"test\"][\"error_raw\"][k]\n",
    "                        for k, v in NN_results[\"test\"][\"error_raw\"].items()\n",
    "                    }\n",
    "\n",
    "                    info = {\n",
    "                        \"val_loss\": NN_results[\"val_loss\"],\n",
    "                        \"val_results\": val_result,\n",
    "                        \"val_results_raw\": val_result_raw,\n",
    "                        \"test_results\": test_result,\n",
    "                        \"test_results_raw\": test_result_raw,\n",
    "                        \"model_parameters\": best_hp,\n",
    "                        \"period\": {\"start\": START_YEAR, \"end\": end_year},\n",
    "                        \"look_back_years\": look_back_year,\n",
    "                        \"output_steps\": output_steps,\n",
    "                        \"Var_results\": Var_results,\n",
    "                        \"NN_results\": NN_results,\n",
    "                        \"variables\": variable,\n",
    "                        \"number_of_pca\": number_of_pca,\n",
    "                    }\n",
    "\n",
    "                    results.append(info)\n",
    "\n",
    "          with open(pickle_file_path, \"wb\") as f:\n",
    "              pickle.dump(results, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('test_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "035b554e3549a2b2468cb30fcc59f94af0d4b55bc9ff889feec7e35d12f7b752"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
